{
  "model_name": "DeepSeek-R1-Distill-Llama-8B",
  "experiment_name": "mc_None",
  "max_concurrency": null,
  "max_batch_size": 8,
  "max_draft_len": 4,
  "force_separate_pools": true,
  "memory_before": {
    "allocated_mb": 0.0,
    "reserved_mb": 0.0,
    "max_allocated_mb": 0.0
  },
  "memory_after": {
    "allocated_mb": 15516.63671875,
    "reserved_mb": 15828.0,
    "max_allocated_mb": 16277.119140625
  },
  "memory_diff": {
    "allocated_mb": 15516.63671875,
    "reserved_mb": 15828.0,
    "max_allocated_mb": 16277.119140625
  },
  "creation_time_seconds": 12.116411209106445,
  "num_cuda_graphs": 8,
  "cuda_graph_batch_sizes": [
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8
  ],
  "graph_breakdown": {
    "draft_len_4": 8
  },
  "log_lines": [
    "CUDA Memory Profiling (single run) for DeepSeek-R1-Distill-Llama-8B",
    "Model path: /models/DeepSeek-R1-Distill-Llama-8B",
    "PyTorch version: 2.8.0a0+5228986c39.nv25.06",
    "CUDA available: True",
    "Current CUDA device: 0",
    "CUDA device name: NVIDIA H200",
    "CUDA memory: 139.7 GB",
    "",
    "============================================================",
    "Running experiment: mc_None",
    "max_concurrency: None",
    "max_batch_size: 8",
    "max_draft_len: 4",
    "============================================================",
    "Debug: Resetting memory stats on CUDA device 0",
    "Memory before LLM: {'allocated_mb': 0.0, 'reserved_mb': 0.0, 'max_allocated_mb': 0.0}",
    "Creating LLM instance (includes warmup & CUDA graph capture)...",
    "",
    "Loading safetensors weights in parallel:   0%|          | 0/2 [00:00<?, ?it/s]",
    "Loading safetensors weights in parallel: 100%|##########| 2/2 [00:00<00:00, 147.41it/s]",
    "",
    "Loading weights concurrently:   0%|          | 0/649 [00:00<?, ?it/s]",
    "Loading weights concurrently:  12%|#1        | 77/649 [00:00<00:01, 426.58it/s]",
    "Loading weights concurrently:  19%|#9        | 126/649 [00:00<00:01, 294.64it/s]",
    "Loading weights concurrently:  24%|##4       | 157/649 [00:00<00:02, 214.96it/s]",
    "Loading weights concurrently:  30%|##9       | 192/649 [00:00<00:02, 224.96it/s]",
    "Loading weights concurrently:  33%|###3      | 217/649 [00:00<00:01, 226.03it/s]",
    "Loading weights concurrently:  37%|###7      | 241/649 [00:00<00:01, 227.35it/s]",
    "Loading weights concurrently:  42%|####2     | 273/649 [00:01<00:01, 232.15it/s]",
    "Loading weights concurrently:  52%|#####2    | 340/649 [00:01<00:00, 342.74it/s]",
    "Loading weights concurrently:  58%|#####8    | 378/649 [00:01<00:00, 323.95it/s]",
    "Loading weights concurrently:  64%|######3   | 413/649 [00:01<00:00, 297.17it/s]",
    "Loading weights concurrently:  69%|######9   | 448/649 [00:01<00:00, 292.63it/s]",
    "Loading weights concurrently:  75%|#######5  | 488/649 [00:01<00:00, 313.26it/s]",
    "Loading weights concurrently:  81%|########1 | 528/649 [00:01<00:00, 325.52it/s]",
    "Loading weights concurrently:  87%|########6 | 562/649 [00:01<00:00, 305.48it/s]",
    "Loading weights concurrently:  92%|#########1| 594/649 [00:02<00:00, 263.24it/s]",
    "Loading weights concurrently:  96%|#########6| 624/649 [00:02<00:00, 269.94it/s]",
    "Loading weights concurrently: 100%|##########| 649/649 [00:02<00:00, 247.94it/s]",
    "Model init total -- 7.26s",
    "LLM creation took: 12.12 seconds",
    "Memory after LLM: {'allocated_mb': 15516.63671875, 'reserved_mb': 15828.0, 'max_allocated_mb': 16277.119140625}",
    "Memory difference: {'allocated_mb': 15516.63671875, 'reserved_mb': 15828.0, 'max_allocated_mb': 16277.119140625}",
    "Number of CUDA graphs captured (total): 8",
    "CUDA graph batch sizes: [1, 2, 3, 4, 5, 6, 7, 8]",
    "CUDA graphs by draft length (counts): {'draft_len_4': 8}",
    "Memory allocator state:",
    "  - Reserved: 15828.0 MB",
    "  - Allocated: 15516.6 MB",
    "  - Fragmentation: 311.4 MB",
    "  - Efficiency: 98.0%",
    "Debug: Resetting memory stats on CUDA device 0"
  ]
}