{
  "model_name": "DeepSeek-R1-Distill-Llama-8B",
  "experiment_name": "mc_16",
  "max_concurrency": 16,
  "max_batch_size": 128,
  "max_draft_len": 4,
  "force_separate_pools": true,
  "memory_before": {
    "allocated_mb": 0.0,
    "reserved_mb": 0.0,
    "max_allocated_mb": 0.0
  },
  "memory_after": {
    "allocated_mb": 15521.17041015625,
    "reserved_mb": 21616.0,
    "max_allocated_mb": 16245.17431640625
  },
  "memory_diff": {
    "allocated_mb": 15521.17041015625,
    "reserved_mb": 21616.0,
    "max_allocated_mb": 16245.17431640625
  },
  "creation_time_seconds": 22.909352779388428,
  "num_cuda_graphs": 68,
  "cuda_graph_batch_sizes": [
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19,
    20,
    21,
    22,
    23,
    24,
    25,
    26,
    27,
    28,
    29,
    30,
    31,
    32,
    64,
    128
  ],
  "graph_breakdown": {
    "draft_len_4": 34,
    "draft_len_0": 34
  },
  "log_lines": [
    "CUDA Memory Profiling (single run) for DeepSeek-R1-Distill-Llama-8B",
    "Model path: /models/DeepSeek-R1-Distill-Llama-8B",
    "PyTorch version: 2.8.0a0+5228986c39.nv25.06",
    "CUDA available: True",
    "Current CUDA device: 0",
    "CUDA device name: NVIDIA H200",
    "CUDA memory: 139.7 GB",
    "",
    "============================================================",
    "Running experiment: mc_16",
    "max_concurrency: 16",
    "max_batch_size: 128",
    "max_draft_len: 4",
    "============================================================",
    "Debug: Resetting memory stats on CUDA device 0",
    "Memory before LLM: {'allocated_mb': 0.0, 'reserved_mb': 0.0, 'max_allocated_mb': 0.0}",
    "Creating LLM instance (includes warmup & CUDA graph capture)...",
    "",
    "Loading safetensors weights in parallel:   0%|          | 0/2 [00:00<?, ?it/s]",
    "Loading safetensors weights in parallel: 100%|##########| 2/2 [00:00<00:00, 164.96it/s]",
    "",
    "Loading weights concurrently:   0%|          | 0/649 [00:00<?, ?it/s]",
    "Loading weights concurrently:  12%|#1        | 77/649 [00:00<00:01, 341.71it/s]",
    "Loading weights concurrently:  19%|#9        | 126/649 [00:00<00:02, 229.44it/s]",
    "Loading weights concurrently:  23%|##3       | 150/649 [00:00<00:02, 191.78it/s]",
    "Loading weights concurrently:  26%|##6       | 169/649 [00:00<00:02, 179.84it/s]",
    "Loading weights concurrently:  31%|###       | 200/649 [00:00<00:02, 191.80it/s]",
    "Loading weights concurrently:  35%|###5      | 228/649 [00:01<00:02, 179.58it/s]",
    "Loading weights concurrently:  38%|###8      | 248/649 [00:01<00:02, 183.06it/s]",
    "Loading weights concurrently:  51%|#####1    | 332/649 [00:01<00:01, 313.17it/s]",
    "Loading weights concurrently:  56%|#####6    | 366/649 [00:01<00:00, 307.68it/s]",
    "Loading weights concurrently:  61%|######1   | 398/649 [00:01<00:00, 304.60it/s]",
    "Loading weights concurrently:  66%|######6   | 429/649 [00:01<00:00, 275.13it/s]",
    "Loading weights concurrently:  72%|#######2  | 468/649 [00:01<00:00, 286.85it/s]",
    "Loading weights concurrently:  77%|#######6  | 498/649 [00:02<00:00, 268.32it/s]",
    "Loading weights concurrently:  81%|########1 | 528/649 [00:02<00:00, 252.94it/s]",
    "Loading weights concurrently:  85%|########5 | 554/649 [00:02<00:00, 242.68it/s]",
    "Loading weights concurrently:  91%|#########1| 592/649 [00:02<00:00, 268.44it/s]",
    "Loading weights concurrently:  96%|#########5| 620/649 [00:02<00:00, 181.89it/s]",
    "Loading weights concurrently:  99%|#########8| 642/649 [00:02<00:00, 158.73it/s]",
    "Loading weights concurrently: 100%|##########| 649/649 [00:03<00:00, 212.33it/s]",
    "Model init total -- 7.92s",
    "LLM creation took: 22.91 seconds",
    "Memory after LLM: {'allocated_mb': 15521.17041015625, 'reserved_mb': 21616.0, 'max_allocated_mb': 16245.17431640625}",
    "Memory difference: {'allocated_mb': 15521.17041015625, 'reserved_mb': 21616.0, 'max_allocated_mb': 16245.17431640625}",
    "Number of CUDA graphs captured (total): 68",
    "CUDA graph batch sizes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 64, 128]",
    "CUDA graphs by draft length (counts): {'draft_len_4': 34, 'draft_len_0': 34}",
    "Memory allocator state:",
    "  - Reserved: 21616.0 MB",
    "  - Allocated: 15521.2 MB",
    "  - Fragmentation: 6094.8 MB",
    "  - Efficiency: 71.8%",
    "Debug: Resetting memory stats on CUDA device 0"
  ]
}